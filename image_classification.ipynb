{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2bf71b-b177-4dd1-b2f2-7b5e44d36a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3363ce-5999-411f-9ed3-9730642bd73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0b20ed-aa16-4046-ab8f-87c8bb96975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations for data augmentation and normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24eac3cb-73e9-47ff-9526-91e3d1fd1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "data_dir = 'dataset'\n",
    "\n",
    "# Create data loaders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "#image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77cc5684-bd96-43e8-bec9-d7e712ae2e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 687, 'val': 200}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d44f70-28a6-42c8-b733-85f91a91fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinj\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shinj\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\shinj/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet-18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final classification layer\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
    "\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa764c6-9a28-470d-bc9f-52a1ef62d5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3655 Acc: 0.8428\n",
      "val Loss: 0.1056 Acc: 0.9450\n",
      "train Loss: 0.3691 Acc: 0.8370\n",
      "val Loss: 0.1813 Acc: 0.9200\n",
      "train Loss: 0.4129 Acc: 0.8166\n",
      "val Loss: 0.1064 Acc: 0.9500\n",
      "train Loss: 0.4251 Acc: 0.8166\n",
      "val Loss: 0.1083 Acc: 0.9600\n",
      "val Loss: 0.1323 Acc: 0.9450\n",
      "train Loss: 0.3709 Acc: 0.8370\n",
      "val Loss: 0.1081 Acc: 0.9550\n",
      "train Loss: 0.4167 Acc: 0.8195\n",
      "val Loss: 0.0962 Acc: 0.9550\n",
      "train Loss: 0.3979 Acc: 0.8384\n",
      "val Loss: 0.0968 Acc: 0.9650\n",
      "train Loss: 0.3805 Acc: 0.8370\n",
      "val Loss: 0.1151 Acc: 0.9550\n",
      "train Loss: 0.4009 Acc: 0.8413\n",
      "val Loss: 0.1192 Acc: 0.9450\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79d9bdbb-b245-47d3-822e-4484dd99ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'flower_classification_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e8fc93c-87ac-46a7-865e-4622d370d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinj\\AppData\\Local\\Temp\\ipykernel_10188\\2813580281.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('flower_classification_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the saved model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1000)  # Adjust to match the original model's output units\n",
    "model.load_state_dict(torch.load('flower_classification_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Create a new model with the correct final layer\n",
    "new_model = models.resnet18(pretrained=True)\n",
    "new_model.fc = nn.Linear(new_model.fc.in_features, 2)  # Adjust to match the desired output units\n",
    "\n",
    "# Copy the weights and biases from the loaded model to the new model\n",
    "new_model.fc.weight.data = model.fc.weight.data[0:2]  # Copy only the first 2 output units\n",
    "new_model.fc.bias.data = model.fc.bias.data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b076c326-a0ec-4f5a-86c5-b3ce6e63fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the unseen image\n",
    "image_path = 'test.jpg'  # Replace with the path to your image\n",
    "image = Image.open(image_path)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = preprocess(image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58893b09-c37c-4f20-a04e-e83404e544e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: daisy\n"
     ]
    }
   ],
   "source": [
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# Get the predicted class\n",
    "_, predicted_class = output.max(1)\n",
    "\n",
    "# Map the predicted class to the class name\n",
    "class_names = ['daisy', 'dandelion']  # Make sure these class names match your training data\n",
    "predicted_class_name = class_names[predicted_class.item()]\n",
    "\n",
    "print(f'The predicted class is: {predicted_class_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
